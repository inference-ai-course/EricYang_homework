{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer in the\u000bGenerative AI Era \n",
    "## lecture 1 - Prompt Engineering with Jupyter Notebook \n",
    "### Introduction\n",
    "This notebook introduces prompt engineering techniques to effectively interact with large language models (LLMs). You'll learn how to craft prompts for various tasks, including summarization, inference, transformation, and expansion\n",
    "\n",
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages/python_autocite-0.0.4-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (1.3.5)\n",
      "Collecting openai\n",
      "  Using cached openai-1.70.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (4.66.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/scottlai/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Using cached openai-1.70.0-py3-none-any.whl (599 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.3.5\n",
      "    Uninstalling openai-1.3.5:\n",
      "      Successfully uninstalled openai-1.3.5\n",
      "Successfully installed openai-1.70.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and set your OpenAI API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI(api_key='your-api-key-here')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic Prompting\n",
    "Let's start with a simple prompt to generate a response from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Modify the prompt to ask about the capital of Germany.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Summarization\n",
    "You can use prompts to summarize text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is the simulation of human intelligence in machines designed to think and learn, with applications in fields such as healthcare, finance, and transportation.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn. It has applications in various fields, including healthcare, finance, and transportation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Summarize the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Try summarizing a longer article or passage of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Information Extraction\n",
    "Extract specific information from a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: John Doe  \n",
      "Occupation: Research Scientist\n",
      "Name: John Doe  \n",
      "Occupation: Research Scientist\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n",
    "text = \"\"\"\n",
    "John Doe, a 29-year-old software engineer from San Francisco, recently joined OpenAI as a research scientist.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Extract the name and occupation from the following text:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Extract the age and location from the same text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transformation\n",
    "Transform text from one format or style to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le temps est agréable aujourd'hui.\n"
     ]
    }
   ],
   "source": [
    "text = \"The weather is nice today.\"\n",
    "\n",
    "prompt = f\"Translate the following text to French:\\n{text}\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Translate a different sentence to Spanish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Expansion\n",
    "Expand a short prompt into a more detailed response.​\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in the misty mountains of Eldoria, there lived a dragon named Zephyr. Unlike the other dragons who reveled in hoarding gold and terrorizing villages, Zephyr had a curious mind and a heart full of dreams. He often gazed down from his lofty perch, watching the humans below as they tapped away at their glowing screens, creating wondrous things with their strange symbols and languages.\n",
      "\n",
      "One day, while exploring a forgotten cave, Zephyr stumbled upon an ancient tome. Its pages were filled with intricate diagrams and strange characters. As he flipped through the book, he realized it was a guide to coding—a language that could bring ideas to life through the magic of technology. Intrigued, Zephyr decided he would learn to code.\n",
      "\n",
      "At first, it was a daunting task. His massive claws were not suited for the delicate tapping of a keyboard. But Zephyr was determined. He fashioned a makeshift keyboard from stones and twigs, and with a little help from the wind, he learned to manipulate the keys with his breath. The first few lines of code were clumsy, but with each attempt, he grew more adept.\n",
      "\n",
      "Days turned into weeks, and Zephyr immersed himself in the world of programming. He learned about variables, loops, and functions, and soon he was creating simple programs that made the wind dance and the clouds swirl. The other dragons watched in bewilderment as Zephyr transformed from a fearsome beast into a master of code.\n",
      "\n",
      "One fateful day, a terrible storm swept through Eldoria, threatening the nearby village of Willowbrook. The villagers were terrified as the winds howled and the rain poured down in torrents. Zephyr, sensing their fear, decided to use his newfound skills to help. He coded a program that would summon a protective barrier of wind around the village, shielding it from the storm’s fury.\n",
      "\n",
      "As the villagers huddled together, they were astonished to see a shimmering wall of air rise up around them, deflecting the rain and calming the winds. When the storm finally passed, they emerged to find Zephyr hovering above, his scales glistening in the sunlight.\n",
      "\n",
      "“Thank you, great dragon!” the village elder called out, awe in his voice. “You have saved us!”\n",
      "\n",
      "Zephyr, once feared and misunderstood, felt a warmth in his heart. He realized that coding had not only given him a new purpose but had also bridged the gap between dragons and humans. From that day forward, he became a protector of the village, using his coding skills to help them with their problems, whether it was creating a weather app or designing a system to keep their crops safe from pests.\n",
      "\n",
      "As the years passed, Zephyr became a legend, not just as a dragon, but as a wise mentor who taught both dragons and humans the art of coding. Together, they built a harmonious community where magic and technology intertwined, proving that even the fiercest of creatures could learn, adapt, and change the world for the better.\n",
      "\n",
      "And so, in the heart of Eldoria, the dragon who learned to code became a symbol of hope, creativity, and the power of knowledge, inspiring generations to come.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a short story about a dragon who learns to code.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Modify the prompt to write a poem about a robot exploring space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Role-based Prompting\n",
    "Instruct the model to respond in a specific role or persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a perfect omelette is a skill that combines technique, timing, and a bit of finesse. Here’s a step-by-step guide to help you achieve that fluffy, delicious result:\n",
      "\n",
      "### Ingredients:\n",
      "- 2-3 large eggs (preferably fresh)\n",
      "- Salt (to taste)\n",
      "- Freshly ground black pepper (to taste)\n",
      "- 1-2 tablespoons of butter (or oil)\n",
      "- Optional fillings: cheese, herbs, vegetables, meats, etc.\n",
      "\n",
      "### Equipment:\n",
      "- Non-stick skillet (8-10 inches)\n",
      "- Whisk or fork\n",
      "- Spatula\n",
      "- Bowl\n",
      "\n",
      "### Instructions:\n",
      "\n",
      "1. **Prep Your Ingredients:**\n",
      "   - If you’re using fillings (like cheese, herbs, or vegetables), prepare them in advance. Chop vegetables finely and pre-cook any that require longer cooking times (like mushrooms or bell peppers).\n",
      "\n",
      "2. **Whisk the Eggs:**\n",
      "   - Crack the eggs into a bowl. Add a pinch of salt and pepper. Whisk vigorously until the yolks and whites are fully combined and the mixture is slightly frothy. This incorporates air, which helps create a fluffy texture.\n",
      "\n",
      "3. **Heat the Skillet:**\n",
      "   - Place your non-stick skillet over medium-low heat. Add the butter and let it melt, swirling it around to coat the bottom of the pan evenly. The butter should foam but not brown.\n",
      "\n",
      "4. **Add the Eggs:**\n",
      "   - Once the butter is melted and slightly bubbling, pour in the whisked eggs. Allow them to sit undisturbed for a few seconds until they start to set around the edges.\n",
      "\n",
      "5. **Stir Gently:**\n",
      "   - Using a spatula, gently stir the eggs in a circular motion, pulling the cooked edges toward the center while tilting the pan to let the uncooked eggs flow to the edges. This technique helps create a uniform texture.\n",
      "\n",
      "6. **Let It Set:**\n",
      "   - After about 30 seconds of stirring, stop and let the omelette cook undisturbed. You want the bottom to set while the top remains slightly runny. This usually takes about 1-2 minutes, depending on your heat.\n",
      "\n",
      "7. **Add Fillings:**\n",
      "   - When the omelette is mostly set but still slightly runny on top, add your desired fillings to one half of the omelette. Be careful not to overfill, as this can make it difficult to fold.\n",
      "\n",
      "8. **Fold the Omelette:**\n",
      "   - Using your spatula, gently fold the omelette in half over the fillings. Let it cook for another 30 seconds to 1 minute, allowing the inside to finish cooking and the cheese (if used) to melt.\n",
      "\n",
      "9. **Plate and Serve:**\n",
      "   - Carefully slide the omelette onto a plate. You can garnish it with fresh herbs or additional seasoning if desired. Serve immediately while it’s warm and fluffy.\n",
      "\n",
      "### Tips for Perfection:\n",
      "- **Egg Quality:** Use the freshest eggs you can find for the best flavor and texture.\n",
      "- **Temperature Control:** Cooking on medium-low heat is key to preventing the eggs from browning too much and ensuring a tender omelette.\n",
      "- **Experiment with Fillings:** Classic combinations include cheese and herbs, but feel free to get creative with your favorite ingredients.\n",
      "- **Practice Makes Perfect:** Don’t be discouraged if your first few attempts aren’t perfect. With practice, you’ll develop a feel for the timing and technique.\n",
      "\n",
      "Enjoy your perfect omelette!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"As a professional chef, explain how to make a perfect omelette.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6: Ask the model to explain a complex topic as if it were a kindergarten teacher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Few-shot Prompting\n",
    "Provide examples to guide the model's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French: Bonne nuit\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following English phrases to French:\n",
    "\n",
    "English: Hello\n",
    "French: Bonjour\n",
    "\n",
    "English: Thank you\n",
    "French: Merci\n",
    "\n",
    "English: Good night\n",
    "French:\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Chain-of-Thought Prompting\n",
    "Encourage the model to explain its reasoning step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the problem, we first need to understand the rate at which the machines produce widgets.\n",
      "\n",
      "From the information given:\n",
      "- 5 machines take 5 minutes to make 5 widgets.\n",
      "\n",
      "This means that each machine makes 1 widget in 5 minutes. \n",
      "\n",
      "Now, let's break it down:\n",
      "- The rate of 1 machine is 1 widget in 5 minutes.\n",
      "- Therefore, in 5 minutes, 1 machine can produce 1 widget.\n",
      "\n",
      "Now, if we have 100 machines, we can calculate how many widgets they can produce in the same 5 minutes:\n",
      "- In 5 minutes, 100 machines will produce 100 widgets (since each machine produces 1 widget in that time).\n",
      "\n",
      "Thus, it would still take 5 minutes for 100 machines to make 100 widgets.\n",
      "\n",
      "So, the answer is **5 minutes**.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"If it takes 5 machines 5 minutes to make 5 widgets, how long would it take 100 machines to make 100 widgets? Explain your reasoning.\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 8: Pose a different math problem and ask for a step-by-step solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. System Prompts\n",
    "System prompts allow you to set the behavior and role of the AI model before user interaction. By defining a system message, you can influence how the model responds to subsequent user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data privacy is crucial for several reasons:\n",
      "\n",
      "1. **Protection of Personal Information**: It safeguards individuals' personal data from unauthorized access, misuse, or exploitation, ensuring that sensitive information like financial details, health records, and personal identifiers remain confidential.\n",
      "\n",
      "2. **Trust and Reputation**: Organizations that prioritize data privacy build trust with their customers. A strong reputation for protecting data can enhance customer loyalty and attract new clients.\n",
      "\n",
      "3. **Legal Compliance**: Many jurisdictions have laws and regulations (e.g., GDPR, CCPA) that mandate data protection practices. Non-compliance can lead to significant legal penalties and fines.\n",
      "\n",
      "4. **Prevention of Identity Theft**: Effective data privacy measures help prevent identity theft and fraud, protecting individuals from financial loss and emotional distress.\n",
      "\n",
      "5. **Business Continuity**: Data breaches can disrupt business operations. Ensuring data privacy helps mitigate risks associated with data loss and breaches, contributing to overall business resilience.\n",
      "\n",
      "6. **Ethical Responsibility**: Organizations have an ethical obligation to respect individuals' privacy rights and handle their data responsibly, fostering a culture of accountability.\n",
      "\n",
      "7. **Innovation and Growth**: By establishing robust data privacy practices, companies can innovate and leverage data analytics while maintaining consumer trust, leading to sustainable growth.\n",
      "\n",
      "In summary, data privacy is essential for protecting individuals, maintaining trust, ensuring compliance, and fostering a responsible data-driven environment.\n"
     ]
    }
   ],
   "source": [
    "def get_completion_with_system_prompt(system_prompt, user_prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Define the system and user prompts\n",
    "system_prompt = \"You are a helpful assistant that provides concise and accurate information.\"\n",
    "user_prompt = \"Can you explain the importance of data privacy?\"\n",
    "\n",
    "response = get_completion_with_system_prompt(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 9: Modify the system_prompt to make the assistant respond in a humorous tone. Observe how the responses change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Utilized prompt\n",
    "how different prompt types—system prompts, user prompts, and assistant prompts—can be utilized in an LLM invocation using the OpenAI API, let's walk through examples in both contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington took office as the first president of the United States on April 30, 1789.\n"
     ]
    }
   ],
   "source": [
    "# Define the conversation with different roles\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant knowledgeable in history.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who was the first president of the United States?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"George Washington was the first president of the United States.\"},\n",
    "    {\"role\": \"user\", \"content\": \"When did he take office?\"}\n",
    "]\n",
    "\n",
    "# Get the model's response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Output the assistant's reply\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Creating an AI Agent\n",
    "An AI agent can perform tasks autonomously based on user instructions. By defining functions and allowing the model to decide when to use them, you can create interactive and functional agents.​\n",
    "\n",
    "Example: AI Agent for Basic Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# Define available functions\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract_numbers(a, b):\n",
    "    return a - b\n",
    "\n",
    "# Function to get the model's response\n",
    "def get_agent_response(user_prompt, model=\"gpt-4\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_numbers\",\n",
    "                \"description\": \"Add two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"subtract_numbers\",\n",
    "                \"description\": \"Subtract two numbers\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"a\": {\"type\": \"number\", \"description\": \"The first number\"},\n",
    "                        \"b\": {\"type\": \"number\", \"description\": \"The second number\"}\n",
    "                    },\n",
    "                    \"required\": [\"a\", \"b\"]\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "\n",
    "    if response_message.function_call:\n",
    "        function_name = response_message.function_call.name\n",
    "        arguments = json.loads(response_message.function_call.arguments)\n",
    "        if function_name == \"add_numbers\":\n",
    "            result = add_numbers(**arguments)\n",
    "        elif function_name == \"subtract_numbers\":\n",
    "            result = subtract_numbers(**arguments)\n",
    "        else:\n",
    "            result = \"Function not recognized.\"\n",
    "        return result\n",
    "    else:\n",
    "        return response_message.content\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"What is 15 minus 7?\"\n",
    "response = get_agent_response(user_prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 10: Extend the agent by adding a function that multiplies two numbers. Test the agent with prompts that require multiplication."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
